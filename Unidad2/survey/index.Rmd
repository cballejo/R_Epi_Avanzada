---
title: "**Estimaciones con IC en muestras complejas con R**"
author: ""
date: ""
output:
  html_document:
    css: style.css
    toc: true
    toc_float: true
    toc_collapsed: false
    toc_depth: 4
number_sections: true
anchor_sections: true
theme: lumen
---

```{r, message=FALSE, echo=F}
knitr::opts_chunk$set(comment=NA, dpi = 300, message = F, warning = F)
```

<br>

*Este material es parte de la* ***Unidad 2 del Curso de Epidemiología - Nivel Avanzado del Instituto Nacional de Epidemiología "Dr. Juan H. Jara" - ANLIS v2024***

<br>

<center><p xmlns:cc="http://creativecommons.org/ns#" xmlns:dct="http://purl.org/dc/terms/"><a property="dct:title" rel="cc:attributionURL" href="https://cballejo.github.io/R_Epi_Avanzada/Unidad2/survey/">Estimaciones con IC en muestras complejas con R</a> por <a rel="cc:attributionURL dct:creator" property="cc:attributionName" href="http://www.ine.gov.ar">Christian Ballejo - Instituto Nacional de Epidemiología</a> bajo licencia <a href="http://creativecommons.org/licenses/by-nc/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;">CC BY-NC 4.0<img style="height:22px!important;margin-left:3px;vertical-align:text-bottom;" src="https://mirrors.creativecommons.org/presskit/icons/cc.svg?ref=chooser-v1"><img style="height:22px!important;margin-left:3px;vertical-align:text-bottom;" src="https://mirrors.creativecommons.org/presskit/icons/by.svg?ref=chooser-v1"><img style="height:22px!important;margin-left:3px;vertical-align:text-bottom;" src="https://mirrors.creativecommons.org/presskit/icons/nc.svg?ref=chooser-v1"></a></p></center>


<br> 
<br> 

## Introducción

En los estudios epidemiológicos de corte transversal, muchas veces se realizan y/o utilizan encuestas poblacionales para estimar la frecuencia de determinadas características de salud o de factores de riesgo en la población.

Estas encuestas enfrentan restricciones prácticas que hacen que el muestreo aleatorio simple (MAS) no sea factible o no sea conveniente por costoso en infraestructura, tiempo y dinero. Por lo tanto resulta necesario recurrir a otras alternativas de muestreo, como la estratificación, la selección en etapas, la formación de conglomerados o el empleo de probabilidades de selección desiguales. 

Los diseños muestrales que incorporan combinaciones de estas estrategias se denominan complejos, por contraste con el MSA, en el que las unidades muestrales se seleccionan independientemente unas de otras y todas tienen igual probabilidad de selección y distribución.

Realizar estimaciones acompañadas de sus intervalos de confianza (IC) en estas bases de datos sin tener en cuenta el efecto del diseño muestral, los dominios de estimación y los factores de expansión puede producir resultados erróneos.

### Algunas definiciones necesarias

**Estratos**:  son subpoblaciones "naturales" que, a priori, son homogéneos en su interior pero heterogéneos entre sí. 

El diseño de la encuesta se hace de modo que se garantiza cubrir adecuadamente todos los estratos de interés. Algunas variables de estratos habituales son: sexo, edad (como grupo etario), nivel de educación,  urbano/rural, etc.

**Conglomerados**: son unidades definidas dentro de cada estrato (si es muestreo polietápico), cuyo tamaño es conocido. 

Lo ideal es que la población dentro de un conglomerado sea lo más heterogénea posible, pero debe haber homogeneidad entre los conglomerados. Cada grupo debe ser una representación a pequeña escala de la población total. Los grupos deben ser mutuamente excluyentes y colectivamente exhaustivos.

**Probabilidad de inclusión**: es la probabilidad que cada unidad tiene de estar incluida en la muestra. En los muestreos complejos polietápicos se obtiene, en general, multiplicando las probabilidades asociadas al estrato, a cada unidad primaria de muestreo (PSU) dentro del estrato, y a la unidad de segunda etapa dentro cada PSU.

**Dominios de estimación**: se definen como subconjuntos de la población objetivo cuyos elementos pueden ser identificados en el marco muestral sin ambigüedad, y en los que se permite desagregar los resultados de la encuesta.

Es aconsejable respetar estos dominios de estimación  y no realizar inferencia de parámetros de interés para otros dominios no previstos que conlleva estimaciones inválidas.

**Factor de expansión**: es el valor asociado a cada unidad elegible y que responde a la muestra, que se construye a partir de la inversa de la probabilidad de inclusión de cada unidad o peso muestral inicial.

Puede incluir distintos tipos de ajustes, para disminuir en lo posible los errores de cobertura y de no respuesta que afectan a la encuesta, y ser tratados por un proceso de calibración que lleva en general a ganar eficiencia y precisión en las estimaciones. 

Los factores de expansión finales son los que se emplean tanto para generar todas las estimaciones de una encuesta, como en los cálculos del error muestral al determinar la precisión alcanzada.

**Efecto de diseño (DEFF por sus siglas en inglés)**: mide la pérdida en precisión al utilizar un diseño muestral complejo en lugar de un diseño aleatorio simple, por ejemplo, un efecto de diseño de 1,5 indica que la varianza del diseño complejo es 1,5 veces más grande que la varianza de un diseño aleatorio simple, en otras palabras se dio un aumento en la varianza de un 50%.


## Paquete survey de R

El paquete más conocido y utilizado del lenguaje R para trabajar con datos provenientes de muestreos complejos es **survey**. Desarrollado por *Thomas Lumley* que a su vez es autor del libro *Complex Surveys - A Guide to Analysis Using R (2010)*.

La versión actual publicada en CRAN es la 4.4.2 y en el siguiente [enlace](http://r-survey.r-forge.r-project.org/survey/index.html) se encuentra información oficial sobre la librería.

Las funciones que lo integran utilizan en sus argumentos la sintaxis fórmula preferentemente y no son compatibles con el universo "ordenado" de tidyverse.

Existe un paquete "wrapper" llamado **srvyr** que incorpora sintaxis *tidy*, haciendo uso de tuberías y funciones tales como `group_by()`, `summarise()`, entre otras. 

Se activa, como todos los paquetes, con:

```{r, message=F, warning=F}
library(srvyr)
```


### Especificación del diseño de la muestra

El primer paso para trabajar con las funciones de **srvyr** es crear un objeto con la información relacionada con el diseño muestral.

Esta tarea se realiza con la función `svydesign()` que tiene estos argumentos principales:


```{r, eval=FALSE}
datos %>%                       # tabla de datos 
  as_survey_design(ids = ..., 
                   strata = ..., 
                   variables = ...,
                   fpc = ...,
                   nest = F,
                   weights = ...)
```

donde:

- **ids**: Variables que especifican identificadores de conglomerados desde el nivel más grande hasta el nivel más pequeño (dejar el argumento vacío, `NULL`, 1 o 0 indica que no hay conglomerados).


- **strata**: Variables que identifican a los estratos. Si no hay estratos, se ignora esta especificación.

Usualmente, se declara a partir de una variable. Por ejemplo, si la variable ESTRATO define los estratos, sería,

```{r, eval=FALSE}
datos %>%
  as_survey_design(..., 
                   strata = ESTRATO, 
                   ...)
```

- **variables**: Variables que se incluirán en el diseño. El valor predeterminado es todas las variables de datos.

- **fpc**: Variables con el factor de corrección por población finita. 

- **nest**: Si es TRUE, re-etiqueta los conglomerados considerando anidamiento dentro de los estratos. Necesario activar cuando las etiquetas de las categorías de los conglomerados en los distintos estratos se llaman igual.

- **weights**: Variables de ponderación de cada observación (inverso a la probabilidad).

Los argumentos mínimos que debemos definir dependerá de la estructura muestral de la base de datos que estemos analizando y de las variables que tengamos a disposición. Habitualmente se tiene referencia de estratos, conglomerados y ponderaciones. También podemos encontrarnos con situaciones donde están definidos los tamaños poblacionales (variable fpc). 

Para ejemplificar vamos a tomar a la **Encuesta Mundial de Salud Escolar** (EMSE) en su tercera edición que en la Argentina se realizó en 2018. Se puede acceder a sus datos abiertos en [EMSE 2018](http://datos.salud.gob.ar/dataset/base-de-datos-de-la-3-encuesta-mundial-de-salud-escolar-emse-con-resultados-nacionales-argentina)

Fue llevada a cabo por el Ministerio de Salud y Desarrollo Social de la Nación, contó con la colaboración de los Ministerios de Educación Nacional y Provinciales, la OPS/OMS Argentina, OPS/OMS Washington y el CDC.

El diseño de muestreo tuvo dos etapas (selección de escuelas y luego de divisiones al azar) para producir una muestra representativa de alumnos de 1º a 5º año de educación media a nivel nacional (8º EGB a 3º polimodal en el caso de la provincia de Buenos Aires) y provincial. Se relevaron 523 escuelas en todo el país y se encuestaron 57.095 alumnos de los cuales se analizaron 56.981 cuestionarios correspondientes a las edades de 13 a 17 años, con una tasa de respuesta global de 63%.

Leemos el archivo de datos con:

```{r, message=F, warning=F}
library(tidyverse)
library(srvyr)

EMSE2018 <- read_csv("EMSE_DatosAbiertos.csv")

dim(EMSE2018) # dimensiones de la tabla de datos
```
Observamos que el dataframe original importado consta de 309 variables y 56981 observaciones. (no mostramos en el documento la salida de la estructura brindada por `glimpse()` por su longitud)

El total de la muestra expandida es de 2637546 estudiantes.

```{r}
EMSE2018 %>%
  summarise(total_expandido = sum(weight))
```

Existen dos variables cuantitativas donde se registraron la altura (q4) y el peso (q5) de los estudiantes encuestados. Antes de generar el objeto de diseño vamos a construir una nueva variable llamada IMC (Índice de Masa Corporal) producto de su cálculo a partir de estas variables.

```{r}
EMSE2018 <- EMSE2018 %>% 
  mutate(IMC = q5/(q4)^2)  # peso sobre talla al cuadrado
```


Las variables relevantes para el diseño muestral que el documento de usuario define son:

- **psu**: Unidades primarias de muestreo (conglomerados)

- **stratum**: Estratos del muestreo

- **weight**: Ponderación


Estas son las tres variables que participaran dentro de los argumentos para definir el objeto de diseño muestral de **survey/srvyr**, junto a un pequeño recorte de variables con las que vamos a trabajar.

- **record** = Nro. de registro

- **q2 / texto_q2** = Sexo

- **q3 / texto_q3** = Grado / año een el que se encuentra el estudiante

- **q4** = Estatura sin zapatos (medido en metros)

- **q5** = Peso sin zapatos (medido en kilogramos)

- **q6 / texto_q6** = Pregunta sobre hambre

- **qn24 / texto_qn24** = Pregunta sobre idea suicida

- **IMC** = Índice de Masa Corporal (recién calculada)

```{r}
d <- EMSE2018 %>%
  as_survey_design(ids = psu,          # conglomerados
                   variables = c(record, psu, stratum, weight, q2, texto_q2, q3, texto_q3, q4, q5, q6, texto_q6, qn24, texto_qn24, IMC),      # variables incluidas en el diseño
                   strata = stratum,   # estratos
                   weights = weight,   # ponderación
                   nest = TRUE)        # anidación

summary(d) 
```

Con la función `summary()` podemos obtener información sobre el objeto creado y detalles del diseño muestral, tales como tamaño de los estratos y cantidad de conglomerados.

Una vez que tenemos creado el objeto *"survey.design"*, que en nuestro ejemplo se denomina **d**, podemos avanzar en el calculo de las estimaciones.

Si bien podemos manipular datos dentro de este formato de diseño utilizando algunas de las funciones de tidyverse (select, mutate, filter y rename) lo conveniente es modificar previamente la estructura de la tabla de datos, ya sea para crear una nueva variable, como hicimos recién con IMC o cambiar una existente y luego generar el objeto con el diseño muestral para poder hacer uso de esos cambios en las estimaciones. 

### Estimaciones

Todos los códigos para las estimaciones comenzaran a partir del objeto de diseño creado inicialmente, llamado **d** en nuestro ejemplo.

En primer lugar tomaremos la variable **IMC** que tiene formato numérico.

La función `survey_mean()` computa estimaciones de medias en diseños complejos usando la sintaxis de tidyverse.

Los siguientes son los argumentos comunes de la función:

- **x**: Variable o expresión o vacía. 

- **na.rm**: Si es TRUE, omite los valores NA de la variable

- **vartype**: Obtiene la variabilidad como uno o más estimadores: error estándar ("se", predeterminado), intervalo de confianza ("ci"), varianza ("var") o coeficiente de variación ("cv").

- **level**: Nivel de confianza (solo se usa si el anterior es "ci")

- **deff**: Si es TRUE, calcula el efecto de diseño para la estimación

Aplicamos la función sobre la variable de IMC dentro de summarise() de tidyverse:

```{r}
d %>%
  summarise(IMC = survey_mean(x = IMC,
              na.rm = T,
              vartype = c("se", "ci", "var", "cv"),
              level = 0.95))

```
El resultado muestra una media de IMC de 22,14, un error estándar de 0,09, un intervalo de confianza al 95% de (21,97-22,31), una varianza de 0,007 y un coeficiente de variación de 0,4 %.

Como nos informan que hubo no respuesta en la encuesta y la faltante de información en altura y/o peso provoca observaciones perdidas en la variable IMC, vamos a ver cuantos de estos valores perdidos tenemos en la variable.

Si deseamos calcular totales, es decir a cuantos estudiantes representa estos valores perdidos podemos usar la función `survey_total()`. 

```{r}
d %>% 
  filter(is.na(IMC)) %>%  # filtramos los NA en IMC
  summarise(IMC_na = survey_total(vartype = "ci"))
```
Hay aproximadamente 976.104 IC 95% (87.820-1.074.088) estudiantes sin valor en la variable IMC del total de la población de 2.637.546 (37 %). 

Si en lugar de la media quisieramos la mediana podemos cambiar la función y usar `survey_median()`.

```{r}
d %>%
  summarise(IMC = survey_median(x = IMC,
              na.rm = T,
              vartype = c("se", "ci", "var", "cv"),
              level = 0.95))

```
Podemos estratificar estas estimaciones haciendo uso del `group_by()`, por ejemplo con la variable sexo del estudiante:

```{r}
d %>% 
  group_by(texto_q2) %>%  # sexo
  summarise(media_IMC = survey_mean(IMC, 
                                    vartype = "ci", 
                                    na.rm = T))
```

Como hay datos perdidos en la variable sexo nos aparece una categoría más en los resultados. Al estar vacía en las estimaciones (evidentemente son no respuestas completas) podemos deshacernos de esa línea con un `filter()`.

```{r}
d %>% 
  filter(!is.na(q2)) %>% 
  group_by(texto_q2) %>% 
  summarise(media_IMC = survey_mean(IMC, 
                                    vartype = "ci", 
                                    na.rm = T))
```

Esta tabla muestra las estimaciones de IMC según sexo con sus intervalos de confianza.

Otra variable de la encuesta es la respuesta a la pregunta "Durante los últimos 30 días ¿con qué frecuencia te quedaste con hambre porque no había suficiente comida en tu hogar?". Las categorías válidas fueron: Nunca - Rara vez - Algunas veces - Casi siempre - Siempre y Dato perdido si no hubo respuesta.

Para abordar estas variables cualitativas donde queremos obtener proporciones el paquete tiene a la función `survey_prop()` que se utiliza luego de declarar la variable de interes en un `group_by()`:

```{r}
d %>% 
  group_by(texto_q6) %>% # variable para la estimacion
  summarise(prop_hambre = survey_prop(vartype = "ci")*100) # usamos 100 para %
```

El resultado muestra las categorías desordenadas en relación a lo que significa cada una respecto a la definición de la pregunta, es decir a la ordinalidad de la variables, aunque si está ordenada respecto a la forma en que lo hace el lenguaje R (alfabético).

Para darle el orden adecuado, deberíamos convertir la variable texto_q6 a factor y declarar correctamente sus niveles. Conviene hacer esto previo a la creación del objeto de diseño pero el paquete también lo permite una vez creado.

```{r}
d <- d  %>%
  mutate(texto_q6 = factor(texto_q6, 
                           levels = c("Nunca", "Rara vez", "Algunas veces", "Casi siempre", "Siempre", "Dato perdido")))
```

Repetimos el código anterior

```{r}
d %>% 
  group_by(texto_q6) %>% # variable para la estimacion
  summarise(prop_hambre = survey_prop(vartype = "ci")*100) # usamos 100 para %
```
El ordenamiento de las categorías ahora es el correcto producto de la transformación a factor.

Para estratificar estas proporciones lo único que debemos hacer es incorporar la variable de agrupamiento dentro del `group_by()`.

```{r}
d %>% 
  group_by(texto_q2, texto_q6) %>% # variable de estratificación y estimacion
  summarise(prop_hambre = survey_prop(vartype = "ci")*100) # usamos 100 para %
```

Este esquema de agrupamientos/estratificaciones se anidan en el orden en que se declaran dentro del `group_by()` siendo la última variable la de estimación. Por ende, los porcentajes también salen anidados, tomando el 100 % de las categorías cada categoría de **texto_q2** para el ejemplo anterior.

Podemos hacer que para el calculo de los porcentajes se tome como denominador el total general de la siguiente forma:

```{r}
d %>% 
  group_by(interact(texto_q2, texto_q6)) %>% # agregamos función interact()
  summarise(prop_hambre = survey_prop(vartype = "ci")*100) # usamos 100 para %
```

Un argumento incluido dentro de las posibilidades de `survey_prop()` es el método para su calculo (prop_method). 

En este documento no vamos a profundizar en los métodos que la función ofrece, solo mencionaremos las posibilidades permitidas según la ayuda del paquete.

El método de `"likelihood"` utiliza la distribución de chi-cuadrado escalada (Rao-Scott) para la loglikelihood de una distribución binomial. 

El método `"asin"` usa la transformación estabilizadora de la varianza para la distribución binomial, la raíz cuadrada del arcoseno, y luego transforma el intervalo a la escala de probabilidad. 

El método `"beta"` usa la función beta incompleta como en `binom.test`, con una tamaño de muestra efectivo basado en la varianza estimada de la proporción. (Korn y Graubard, 1998) 

El método `"mean"` utiliza un intervalo tipo Wald en la escala de probabilidad, igual que `confint()`

De forma predeterminada el argumento toma el método "logit" que ajusta un modelo de regresión logística y calcula un intervalo tipo Wald en la escala logarítmica de probabilidades, que luego se transforma a la escala de probabilidad.

Otra función útil es `survey_count()` que estima el conteo poblacional de las observaciones según categoría.

```{r}
d %>% 
  survey_count(texto_q6,
               vartype = "ci") 
```

Aquí lo usamos acompañando con el intervalo de confianza del 95% (predeterminado).

Ahora tomaremos otra variable de EMSE2018 llamada **qn24** que refiere a la pregunta: "Durante los últimos 12 meses, ¿alguna vez consideraste seriamente la posibilidad de intentar suicidarte?". Sus posibles respuestas son "Si", "No" y el habitual "Dato perdido".

Estimaremos su proporción para toda la población pero también para una subpoblación en particular "3er año/12vo grado nivel Polimodal o 5to año nivel Secundario".

Como es habitual que necesitemos obtener estimaciones en subgrupos o subpoblaciones determinados por categorías definidas de una variable, debemos tener cuidado e interpretar los elementos del muestro para que esas subpoblaciones hayan sido consideradas y por lo tanto estén declaradas como **dominio de estimación**. 

Estos subgrupos requeridos pueden no coincidir con los estratos de la muestra compleja generando un inconveniente para las estimaciones, dado que las ponderaciones muestrales serían correctas pero la probabilidad de muestreo seguramente no, lo que produce estimaciones puntuales correctas con errores estándar incorrectos.

Las funciones del paquete **srvyr** maneja estos detalles sin ningún esfuerzo especial por parte del analista siempre y cuando utilice la muestra completa para definir el objeto de diseño de la encuesta pero no asegura que los resultados tengan la calidad necesaria.

Mostremos el código entonces:

```{r}
d %>% 
  group_by(texto_qn24) %>% 
  summarise(prop_suicidio = survey_prop(vartype = c("ci", "cv"))*100) 
```

```{r}
d %>% 
  filter(q3 == 5) %>%   # codigo 5 de q3 es la subpoblación seleccionada
  group_by(texto_qn24) %>% 
  summarise(prop_suicidio = survey_prop(vartype = c("ci", "cv"))*100)
```

Un 21,0 % IC95%(20,3-21,7) del total de estudiantes dicen haber considerado un intento de suicidio en el último año, mientras que un 18,9 % IC95%(17,5-20,4) dice lo mismo en el grupo de 3er año/12vo grado nivel Polimodal o 5to año nivel Secundario.

Agregamos a los resultados algo importante, que va a garantizar la calidad de la estimaciones y evitar estar informando valores poco confiables para los cuales el muestreo quizás no esté preparado. Este es el **coeficiente de variación** (CV).

Comparativamente vamos a encontrar en la medida que se agreguen filtro o agrupamiento anidados que reduzcan la muestra en la estimación valores más elevados de CV.

Que pasa si filtramos y nos quedamos además solo con las mujeres que respondieron .

```{r}
d %>% 
  filter(q3 == 5, q2 == 2, q6 == 3) %>%   # codigo 5 de q3 es la subpoblación seleccionada
  group_by(texto_qn24) %>% 
  summarise(prop_suicidio = survey_prop(vartype = c("ci", "cv"))*100)
```





## Errores estándar según efecto del diseño

En este punto vamos a comparar estimaciones en función de construir objetos de diseños muestrales diferentes sobre la misma base de datos **nhanes**.

```{r}
# Diseño complejo y pesos
d_complejo <- svydesign(id = ~SDMVPSU, 
                        strata = ~SDMVSTRA, 
                        weights = ~WTMEC2YR, 
                        nest = TRUE,
                        data = nhanes)

# Diseño sin uso de pesos

d_simple <- svydesign(id = ~1, 
                        strata = NULL, 
                        weights = NULL, 
                        data = nhanes)

# Diseño con pesos pero sin estructura compleja
d_ponde <- svydesign(id = ~1, 
                        strata = NULL, 
                        weights = ~WTMEC2YR, 
                        data = nhanes)
```

Tenemos tres diseños distintos: un diseño complejo basado en conglomerados, estratos y pesos, un diseño sólo con pesos y un diseño simple sin ponderación.

Sabemos que el primero es el diseño "real" con el que se llevó a cabo la recolección de los datos.

```{r}
d_complejo

d_ponde

d_simple
```

Ahora ejecutemos la función `svymean()` para estimar la proporción de **HI_COL** en cada caso.

```{r}
col1 <- svymean(~HI_CHOL, 
                d_complejo, 
                deff = T, 
                na.rm = T)

col1

col2 <- svymean(~HI_CHOL, 
                d_ponde, 
                deff = T, 
                na.rm = T)

col2

col3 <- svymean(~HI_CHOL, 
                d_simple, 
                na.rm = T)

col3
```

La estimación puntual (11,21 %) es la misma para los análisis que usan el diseño complejo y los que usan sólo pesos. A su vez es diferente (10,03 %) si las estimaciones se llevan a cabo sin considerar el factor de expansión (muestreo simple). 

Los errores estándar estimados son diferentes para todos los casos porque además se vinculan con la estructura del muestreo (estratos y conglomerados).

Si no se utilizan pesos en las estimaciones, los estimadores no serán representativos de la población muestreada.

Si solo se utilizan pesos sin considerar el diseño complejo, en general, se infravalorará la dispersión de los estimadores, llevando a intervalos de confianza excesivamente estrechos y a niveles de significación reales mayores que los nominales.


### Criterios de calidad en las estimaciones

Todas las estimaciones elaboradas a partir de datos obtenidos por encuestas poblacionales con muestreos complejos están sujetas al error muestral, lo que hace necesario evaluar su validez estadística mediante diversos indicadores de precisión y confiabilidad.

Veamos algunos de estos indicadores de calidad:

#### Coeficiente de variación

Esta medida configura un acercamiento al error de muestreo que permite verificar si la inferencia es válida. 

Se caracteriza por ser proporcional a la amplitud del intervalo de confianza, que provee una versión estandarizada y relativa de la precisión alrededor de la estimación puntual.

Un umbral aproximado de CV mayor a 20%-30% puede asumirse como un valor de referencia útil a nivel regional para señalar una cifra de poco confiable, *Gutiérrez y otros (2020)*.

Para calcular el coeficiente de variación de las estimaciones en R basta con utilizar la función `cv()` e incluir como argumento el objeto de estimación.

```{r}
cv(col_x_gEdad)
```
Observamos que en el grupo de (0-19) la estimación no es tan confiable (CV 30.8 %)

#### Tamaño de muestra

Este criterio debe ser considerado como uno de los más importantes a la hora de decidir la calidad de la estimación. La cobertura de los intervalos de confianza y la distribución de los estimadores dependen de que, tanto el tamaño de la subpoblación como su tamaño de muestra asociado, no sean pequeños. En este espíritu, *Andrés Gutiérrez et al. Cepal (2020)* proponen que todas las estimaciones basadas en un tamaño de muestra menor a 100 unidades deberían ser marcadas como no confiables.

Para obtener tamaños muestrales ponderados de subgrupos podemos aplicar la función `svytotal()`.

```{r}
svytotal(x = ~agecat, 
         design = d)
```

#### Conteo de casos no ponderado 

Cuando la incidencia de un fenómeno es muy baja y el diseño de la encuesta no lo tuvo en cuenta, entonces es posible que las estimaciones asociadas a tamaños, totales y proporciones sobre este fenómeno no sean confiables. Por ejemplo, *National Research Council (2015)* plantea que si el número de casos no ponderados es menor a 50 unidades entonces la estimación no es publicable.

Conocer este valor es sencillo, por ejemplo usando `count()` de dplyr/tidyverse:

```{r, message=F, warning=F}
library(tidyverse)

nhanes %>% 
  count(agecat)
```

## Bibliografía


Luis Carlos Silva Ayçaguer (2020), "Diseño razonado de muestras y captación de datos para la investigación sanitaria", Ediciones Díaz de Santos, S. A.

T. Lumley (2010), "Complex Surveys: A Guide to Analysis Using R". John Wiley and Sons.

Sakshaug, J. W., & West, B. T. (2014). Important considerations when analyzing health survey data collected using a complex sample design. American journal of public health, 104(1), 15–16. https://doi.org/10.2105/AJPH.2013.301515

Bell, B. A., Onwuegbuzie, A. J., Ferron, J. M., Jiao, Q. G., Hibbard, S. T., & Kromrey, J. D. (2012). Use of design effects and sample weights in complex health survey data: a review of published articles using data from 3 commonly used adolescent health surveys. American journal of public health, 102(7), 1399–1405. https://doi.org/10.2105/AJPH.2011.300398

Realizing the Potential of the American Community Survey: Challenges, Tradeoffs, and Opportunities. (2015). Panel on Addressing Priority Technical Issues for the Next Decade of the American Community Survey, Committee on National Statistics, Division of Behavioral and Social Sciences and Education. Washington, DC: The National Academies Press. https://doi.org/10.17226/21653.

Epidat: Material de ayuda programa para análisis epidemiológico de datos. Versión 4.2 (2016),  Consellería de Sanidade, Xunta de Galicia, España; Organización Panamericana de la salud (OPS-OMS); Universidad CES, Colombia.

A. Gutiérrez y otros (2020), “Criterios de calidad en la estimación de indicadores a partir de encuestas de hogares: una aplicación a la migración internacional” serie Estudios Estadísticos, N° 101 (LC/TS.2020/52), Santiago, Comisión Económica para América Latina y el Caribe (CEPAL).

T. Lumley (2020), "survey: analysis of complex survey samples". R package version 4.0.

Greg Freedman Ellis and Ben Schneider (2021). srvyr: 'dplyr'-Like Syntax for Summary Statistics of Survey Data. R package version 1.0.1. https://CRAN.R-project.org/package=srvyr